{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aaa1708-a059-402a-8dbc-1fc721585a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úîÔ∏è Configuration loaded. Using checkpoint: D:\\arabic_readability_project\\results\\hybrid_constrained_samer_regression_v2_readability-arabertv2-d3tok-reg\\checkpoint-24472\n",
      "\n",
      "===== üöÄ STARTING HYBRID DOCUMENT PREDICTION PIPELINE =====\n",
      "\n",
      "Initializing Tokenizer and Disambiguator...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at C:\\Users\\Fatima\\AppData\\Roaming\\camel_tools\\data\\disambig_bert_unfactored\\msa were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SAMER Lexicon from: D:\\arabic_readability_project\\data\\samer_lexicon.tsv\n",
      "Loading model weights from checkpoint: D:\\arabic_readability_project\\results\\hybrid_constrained_samer_regression_v2_readability-arabertv2-d3tok-reg\\checkpoint-24472\n",
      "‚úî All models and data loaded successfully.\n",
      "‚úî Ground truth labels loaded for 210 documents.\n",
      "\n",
      "Processing documents: this will take time...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "906db1a5564e4ae8a9aa61d9454f66fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Documents:   0%|          | 0/210 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úî Successfully created 7286 sentences with features.\n",
      "\n",
      "Generating predictions for all sentences...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregating results...\n",
      "\n",
      "üìà Calculated QWK Score: 0.6430\n",
      "\n",
      "Saving prediction file to: D:\\arabic_readability_project\\submission\\submission_hybrid_document_eval.csv\n",
      "--- ‚úÖ SUCCESS! Submission file 'submission_hybrid_document_eval.zip' created. ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import zipfile\n",
    "import gc\n",
    "\n",
    "from torch.utils.data import Dataset as TorchDataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "from safetensors.torch import load_file\n",
    "from camel_tools.disambig.bert import BERTUnfactoredDisambiguator\n",
    "from camel_tools.tokenizers.word import simple_word_tokenize\n",
    "from camel_tools.utils.dediac import dediac_ar\n",
    "from tqdm.auto import tqdm\n",
    "# --- MODIFICATION: Import for QWK calculation ---\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# =====================================================================================\n",
    "# 1. CONFIGURATION\n",
    "# =====================================================================================\n",
    "MODEL_NAME = \"CAMeL-Lab/readability-arabertv2-d3tok-reg\"\n",
    "TARGET_CLASSES = 19\n",
    "NUM_FEATURES = 7\n",
    "\n",
    "CHECKPOINT_PATH = r\"D:\\arabic_readability_project\\results\\hybrid_constrained_samer_regression_v2_readability-arabertv2-d3tok-reg\\checkpoint-24472\"\n",
    "BASE_DIR = r\"D:\\arabic_readability_project\"\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
    "SUBMISSION_DIR = os.path.join(BASE_DIR, \"submission\")\n",
    "\n",
    "# --- MODIFICATION: Point to your ground truth file ---\n",
    "DOC_TEST_PATH = os.path.join(DATA_DIR, 'doc_test.csv')\n",
    "SAMER_LEXICON_PATH = os.path.join(DATA_DIR, 'samer_lexicon.tsv')\n",
    "\n",
    "# --- MODIFICATION: Update output file names for clarity ---\n",
    "SUBMISSION_PATH = os.path.join(SUBMISSION_DIR, \"submission_hybrid_document_eval.csv\")\n",
    "ZIPPED_SUBMISSION_PATH = os.path.join(SUBMISSION_DIR, \"submission_hybrid_document_eval.zip\")\n",
    "\n",
    "os.makedirs(SUBMISSION_DIR, exist_ok=True)\n",
    "print(f\"‚úîÔ∏è Configuration loaded. Using checkpoint: {CHECKPOINT_PATH}\")\n",
    "\n",
    "\n",
    "# =====================================================================================\n",
    "# 2. FEATURE CALCULATION - WITH THE FINAL API FIX\n",
    "# =====================================================================================\n",
    "def calculate_features_and_d3tok(sentence_text, disambiguator, lexicon_map):\n",
    "    if not isinstance(sentence_text, str) or not sentence_text.strip():\n",
    "        return ([0.0] * NUM_FEATURES, \"\")\n",
    "\n",
    "    try:\n",
    "        tokens = simple_word_tokenize(sentence_text)\n",
    "        disambiguated_sentence = disambiguator.disambiguate(tokens)\n",
    "\n",
    "        d3tok_forms = []\n",
    "        for da in disambiguated_sentence:\n",
    "            if da.analyses and 'd3tok' in da.analyses[0][1]:\n",
    "                d3tok_value = da.analyses[0][1]['d3tok']\n",
    "                if isinstance(d3tok_value, str):\n",
    "                    d3tok_forms.append(dediac_ar(d3tok_value).replace(\"_+\", \" +\").replace(\"+_\", \"+ \"))\n",
    "            elif isinstance(da.word, str): d3tok_forms.append(da.word)\n",
    "        d3tok_text = \" \".join(d3tok_forms)\n",
    "\n",
    "        scores = []\n",
    "        for dw in disambiguated_sentence:\n",
    "            if dw.analyses:\n",
    "                analysis = dw.analyses[0][1]\n",
    "                lemma, pos = analysis.get('lex'), analysis.get('pos')\n",
    "                if pos and isinstance(lemma, str):\n",
    "                    score = lexicon_map.get(f\"{dediac_ar(lemma)}#{pos}\")\n",
    "                    if score is not None: scores.append(score)\n",
    "\n",
    "        avg_readability = np.mean(scores) if scores else 0.0\n",
    "        max_readability = np.max(scores) if scores else 0.0\n",
    "\n",
    "        # This part remains unchanged as per the original script's logic\n",
    "        feature_3, feature_4, feature_5, feature_6, feature_7 = 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "        feature_vector = [avg_readability, max_readability, feature_3, feature_4, feature_5, feature_6, feature_7]\n",
    "\n",
    "        return feature_vector, d3tok_text\n",
    "\n",
    "    except TypeError as e:\n",
    "        error_message = f\"A TypeError occurred processing sentence: >>>{sentence_text}<<< Original error: {e}\"\n",
    "        raise TypeError(error_message)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: An error '{e}' occurred on sentence: '{sentence_text}'. Skipping.\")\n",
    "        return ([0.0] * NUM_FEATURES, \"\")\n",
    "\n",
    "\n",
    "# =====================================================================================\n",
    "# 3. HYBRID MODEL AND DATASET CLASSES (FIXED)\n",
    "# =====================================================================================\n",
    "class HybridRegressionModel(nn.Module):\n",
    "    def __init__(self, model_name, num_extra_features):\n",
    "        super(HybridRegressionModel, self).__init__()\n",
    "        self.transformer = AutoModel.from_pretrained(model_name)\n",
    "        self.regressor = nn.Linear(self.transformer.config.hidden_size + num_extra_features, 1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, extra_features, labels=None):\n",
    "        outputs = self.transformer(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooler_output = outputs.pooler_output\n",
    "        combined_features = torch.cat((pooler_output, extra_features), dim=1)\n",
    "        logits = self.regressor(combined_features).squeeze(-1)\n",
    "\n",
    "        if labels is not None:\n",
    "            loss = nn.MSELoss()(logits, labels.float())\n",
    "            return (loss, logits)\n",
    "        return logits\n",
    "\n",
    "class ReadabilityDataset(TorchDataset):\n",
    "    def __init__(self, texts, features, labels=None, tokenizer_obj=None, max_len=256):\n",
    "        self.texts=texts; self.features=features; self.labels=labels\n",
    "        self.tokenizer=tokenizer_obj; self.max_len=max_len\n",
    "    def __len__(self): return len(self.texts)\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        feature_vec = torch.tensor(self.features[idx], dtype=torch.float)\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text, None, add_special_tokens=True, max_length=self.max_len, padding='max_length', truncation=True\n",
    "        )\n",
    "\n",
    "        item = {\n",
    "            'input_ids': torch.tensor(inputs['input_ids'], dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(inputs['attention_mask'], dtype=torch.long),\n",
    "            'extra_features': feature_vec\n",
    "        }\n",
    "\n",
    "        if self.labels is not None:\n",
    "            item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "\n",
    "        return item\n",
    "\n",
    "# =====================================================================================\n",
    "# 4. PREDICTION LOGIC\n",
    "# =====================================================================================\n",
    "\n",
    "def generate_document_predictions(checkpoint_path):\n",
    "    print(\"\\n===== üöÄ STARTING HYBRID DOCUMENT PREDICTION PIPELINE =====\\n\")\n",
    "    try:\n",
    "        print(\"Initializing Tokenizer and Disambiguator...\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "        disambiguator = BERTUnfactoredDisambiguator.pretrained('msa')\n",
    "\n",
    "        print(f\"Loading SAMER Lexicon from: {SAMER_LEXICON_PATH}\")\n",
    "        lexicon_df = pd.read_csv(SAMER_LEXICON_PATH, sep='\\t')\n",
    "        lexicon_map = lexicon_df.set_index('lemma#pos')['readability (rounded average)'].to_dict()\n",
    "\n",
    "        print(f\"Loading model weights from checkpoint: {checkpoint_path}\")\n",
    "        model = HybridRegressionModel(MODEL_NAME, num_extra_features=NUM_FEATURES)\n",
    "        model.load_state_dict(load_file(os.path.join(checkpoint_path, \"model.safetensors\")))\n",
    "        print(\"‚úî All models and data loaded successfully.\")\n",
    "\n",
    "        # --- MODIFICATION: Read from doc_test.csv and prepare true labels ---\n",
    "        doc_test_df = pd.read_csv(DOC_TEST_PATH)\n",
    "        doc_test_df.dropna(subset=['ID', 'Sentences', 'Readability_Level_19'], inplace=True)\n",
    "        true_labels_map = doc_test_df.set_index('ID')['Readability_Level_19'].to_dict()\n",
    "        print(f\"‚úî Ground truth labels loaded for {len(true_labels_map)} documents.\")\n",
    "\n",
    "        print(\"\\nProcessing documents: this will take time...\")\n",
    "        rows_for_df = []\n",
    "        for _, row in tqdm(doc_test_df.iterrows(), total=len(doc_test_df), desc=\"Processing Documents\"):\n",
    "            doc_id = row['ID']\n",
    "            full_text = row['Sentences']\n",
    "            if isinstance(full_text, str) and full_text.strip():\n",
    "                sentences_list = [s.strip() for s in full_text.split('\\n') if s.strip()]\n",
    "                for sentence in sentences_list:\n",
    "                    features, processed_text = calculate_features_and_d3tok(sentence, disambiguator, lexicon_map)\n",
    "                    rows_for_df.append({'doc_id': doc_id, 'features': features, 'processed_text': processed_text})\n",
    "\n",
    "        if not rows_for_df: raise ValueError(\"No sentences could be extracted.\")\n",
    "        sentence_df = pd.DataFrame(rows_for_df)\n",
    "        print(f\"‚úî Successfully created {len(sentence_df)} sentences with features.\")\n",
    "\n",
    "        trainer = Trainer(model=model, args=TrainingArguments(output_dir=\"./temp_results\", per_device_eval_batch_size=32, report_to=\"none\"))\n",
    "\n",
    "        print(\"\\nGenerating predictions for all sentences...\")\n",
    "        test_dataset = ReadabilityDataset(texts=sentence_df['processed_text'].tolist(), features=sentence_df['features'].tolist(), tokenizer_obj=tokenizer)\n",
    "        raw_predictions = trainer.predict(test_dataset)\n",
    "        sentence_df['raw_prediction'] = raw_predictions.predictions.flatten()\n",
    "\n",
    "        print(\"Aggregating results...\")\n",
    "        doc_predictions = sentence_df.groupby('doc_id')['raw_prediction'].max()\n",
    "\n",
    "        clipped_preds = np.clip(np.round(doc_predictions.values), 0, TARGET_CLASSES - 1)\n",
    "        final_predicted_labels = (clipped_preds + 1).astype(int)\n",
    "\n",
    "        # --- MODIFICATION: Calculate QWK ---\n",
    "        doc_ids_with_preds = doc_predictions.index\n",
    "        final_true_labels = [true_labels_map[doc_id] for doc_id in doc_ids_with_preds]\n",
    "        qwk_score = cohen_kappa_score(final_true_labels, final_predicted_labels, weights='quadratic')\n",
    "        print(f\"\\nüìà Calculated QWK Score: {qwk_score:.4f}\\n\")\n",
    "        # --- End of QWK Calculation ---\n",
    "\n",
    "        submission_df = pd.DataFrame({'Sentence ID': doc_ids_with_preds, 'Prediction': final_predicted_labels})\n",
    "        final_submission_df = pd.DataFrame({'Sentence ID': doc_test_df['ID']}).merge(submission_df, on='Sentence ID', how='left')\n",
    "        final_submission_df['Prediction'] = final_submission_df['Prediction'].fillna(1).astype(int)\n",
    "\n",
    "        print(f\"Saving prediction file to: {SUBMISSION_PATH}\")\n",
    "        final_submission_df.to_csv(SUBMISSION_PATH, index=False)\n",
    "\n",
    "        with zipfile.ZipFile(ZIPPED_SUBMISSION_PATH, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "            zipf.write(SUBMISSION_PATH, arcname=os.path.basename(SUBMISSION_PATH))\n",
    "\n",
    "        print(f\"--- ‚úÖ SUCCESS! Submission file '{os.path.basename(ZIPPED_SUBMISSION_PATH)}' created. ---\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå An unexpected error occurred: {e}\")\n",
    "    finally:\n",
    "        gc.collect()\n",
    "        if 'model' in locals(): del model\n",
    "        if 'trainer' in locals(): del trainer\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "# =====================================================================================\n",
    "# 5. EXECUTE THE SCRIPT\n",
    "# =====================================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    generate_document_predictions(CHECKPOINT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccc7cac-7261-45f4-a616-7c06c1776960",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (barec_env)",
   "language": "python",
   "name": "barec_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
