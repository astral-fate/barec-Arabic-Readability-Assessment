# -*- coding: utf-8 -*-
"""strict barec classfication.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Hcckd4TJOuX8SqTGBiS1-9G2Qtf_Mlk4
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import os
import torch
import zipfile
from sklearn.metrics import cohen_kappa_score
from torch.utils.data import Dataset as TorchDataset
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TrainingArguments,
    Trainer,
    EarlyStoppingCallback
)
# Removed camel_tools imports
# from camel_tools.disambig.bert import BERTUnfactoredDisambiguator
# from camel_tools.tokenizers.word import simple_word_tokenize
# from camel_tools.utils.dediac import dediac_ar

# --- Configuration (MODIFIED FOR CLASSIFICATION) ---
MODEL_NAME = "CAMeL-Lab/readability-arabertv02-word-CE"
TARGET_CLASSES = 19
NUM_LABELS = TARGET_CLASSES  # MODIFIED: Use 19 labels for classification
BASE_DIR = '.'
DATA_DIR = os.path.join(BASE_DIR, "data")
# MODIFIED: Changed output directory name for clarity
CHECKPOINT_DIR = os.path.join(BASE_DIR, "results_word_cls", f"classification_{MODEL_NAME.split('/')[-1]}")
SUBMISSION_DIR = os.path.join(BASE_DIR, "submission")

os.makedirs(CHECKPOINT_DIR, exist_ok=True)
os.makedirs(SUBMISSION_DIR, exist_ok=True)

# --- File Paths (MODIFIED FOR CLASSIFICATION AND GOOGLE DRIVE) ---
# MODIFIED: Using Google Drive paths for train, dev, and test data
TRAIN_DATA_PATH = '/content/drive/MyDrive/BAREC_Competition/barec/train.csv'
DEV_DATA_PATH = '/content/drive/MyDrive/BAREC_Competition/barec/dev.csv'
TEST_DATA_PATH = '/content/drive/MyDrive/BAREC_Competition/barec/test.csv'

# MODIFIED: Changed submission file names for clarity
SUBMISSION_PATH = os.path.join(SUBMISSION_DIR, "submission_classification_final.csv")
ZIPPED_SUBMISSION_PATH = os.path.join(SUBMISSION_DIR, "submission_classification_final.zip")


# --- DATA LOADING AND PROCESSING (MODIFIED TO REMOVE camel_tools) ---
# Removed preprocess_d3tok function
# def preprocess_d3tok(text, disambiguator):
#     if not isinstance(text, str) or not text.strip():
#         return ""
#     tokens = simple_word_tokenize(text)
#     disambiguated_sentence = disambiguator.disambiguate(tokens)
#     d3tok_forms = []
#     for disambig_word in disambiguated_sentence:
#         if disambig_word.analyses:
#             analysis_dict = disambig_word.analyses[0][1]
#             if 'd3tok' in analysis_dict:
#                 d3tok = dediac_ar(analysis_dict['d3tok']).replace("_+", " +").replace("+_", "+ ")
#                 d3tok_forms.append(d3tok)
#             else:
#                 d3tok_forms.append(disambig_word.word)
#         else:
#             d3tok_forms.append(disambig_word.word)
#     return " ".join(d3tok_forms)


# MODIFIED: Simplified data loading to use specified columns and remove preprocessing
def load_data():
    print("--- Loading BAREC Data ---")
    try:
        train_df = pd.read_csv(TRAIN_DATA_PATH)
        val_df = pd.read_csv(DEV_DATA_PATH)
        test_df = pd.read_csv(TEST_DATA_PATH)

        # MODIFIED: Use 'Sentence' and 'Readability_Level_19' columns
        train_df = train_df[['Sentence', 'Readability_Level_19']].copy()
        val_df = val_df[['Sentence', 'Readability_Level_19']].copy()
        # MODIFIED: Use 'Sentence' and 'ID' for test set
        test_df = test_df[['Sentence', 'ID']].copy() # Assuming 'ID' is the sentence ID column

        # Handle potential missing values
        train_df.dropna(subset=['Sentence', 'Readability_Level_19'], inplace=True)
        val_df.dropna(subset=['Sentence', 'Readability_Level_19'], inplace=True)
        test_df.dropna(subset=['Sentence'], inplace=True)


        train_df['Sentence'] = train_df['Sentence'].astype(str)
        val_df['Sentence'] = val_df['Sentence'].astype(str)
        test_df['Sentence'] = test_df['Sentence'].astype(str)

        # MODIFIED: Ensure label column is integer type
        train_df['Readability_Level_19'] = train_df['Readability_Level_19'].astype(int)
        val_df['Readability_Level_19'] = val_df['Readability_Level_19'].astype(int)


        # Removed camel_tools preprocessing steps
        # print("Initializing BERT Disambiguator for preprocessing...")
        # try:
        #     bert_disambiguator = BERTUnfactoredDisambiguator.pretrained('msa')
        # except Exception as e:
        #     print(f"Could not initialize BERT disambiguator: {e}")
        #     bert_disambiguator = None # Set to None if initialization fails

        # print("Preprocessing data to D3Tok format...")
        # if bert_disambiguator:
        #     train_df['processed_text'] = train_df['text'].apply(lambda x: preprocess_d3tok(x, bert_disambiguator))
        #     val_df['processed_text'] = val_df['text'].apply(lambda x: preprocess_d3tok(x, bert_disambiguator))
        #     test_df['processed_text'] = test_df['text'].apply(lambda x: preprocess_d3tok(x, bert_disambiguator))
        # else:
        #     print("Skipping preprocessing due to disambiguator initialization failure. Using raw text.")
        #     train_df['processed_text'] = train_df['text']
        #     val_df['processed_text'] = val_df['text']
        #     test_df['processed_text'] = test_df['text']

        # MODIFIED: Use original 'Sentence' column as processed text
        train_df['processed_text'] = train_df['Sentence']
        val_df['processed_text'] = val_df['Sentence']
        test_df['processed_text'] = test_df['Sentence']


        print(f"Successfully loaded and processed {len(train_df)} training, {len(val_df)} validation, and {len(test_df)} test records.")
        return train_df, val_df, test_df

    except FileNotFoundError as e:
         print(f"! ERROR: Data file not found: {e}")
         print(f"Please ensure '{TRAIN_DATA_PATH}', '{DEV_DATA_PATH}', and '{TEST_DATA_PATH}' exist in your Google Drive.")
         return None, None, None
    except KeyError as e:
        print(f"! KEY ERROR: Missing required column in data file: {e}")
        print(f"Please ensure your CSV files have 'Sentence' and 'Readability_Level_19' (for train/dev) and 'Sentence' and 'ID' (for test) columns.")
        return None, None, None
    except Exception as e:
        print(f"! ERROR during data loading and processing: {e}")
        return None, None, None


# MODIFIED: Call the updated load_data function
train_df, val_df, test_df = load_data()


if train_df is not None and val_df is not None and test_df is not None:
    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
else:
    print("Stopping script due to data loading or processing failure.")
    import sys
    sys.exit()


# --- DATASET AND METRICS (MODIFIED FOR CLASSIFICATION) ---
class ReadabilityDataset(TorchDataset):
    def __init__(self, texts, labels=None):
        self.encodings = tokenizer(texts, truncation=True, padding="max_length", max_length=256)
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            # MODIFIED: Labels are converted to long for CrossEntropyLoss
            item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)
        return item

    def __len__(self):
        return len(self.encodings.get('input_ids', []))

def compute_metrics(p):
    # MODIFIED: Use argmax to get predicted class from logits
    preds = np.argmax(p.predictions, axis=1)
    labels = p.label_ids
    # MODIFIED: Convert labels back to original scale for QWK calculation (1-19)
    labels_original_scale = labels + 1
    preds_original_scale = preds + 1
    qwk = cohen_kappa_score(labels_original_scale, preds_original_scale, weights='quadratic')
    # MODIFIED: Added accuracy calculation for additional metric
    acc = (preds == labels).mean()
    return {"qwk": qwk, "accuracy": acc}

# --- MODEL TRAINING (MODIFIED FOR CLASSIFICATION) ---
print("\n===== INITIALIZING CLASSIFICATION MODEL AND TRAINER =====\n")

# MODIFIED: Removed `ignore_mismatched_sizes` as the label count now matches the pre-trained model.
model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=NUM_LABELS)

# MODIFIED: Adjust labels to be 0-indexed for training and validation, use 'Readability_Level_19' column
train_dataset = ReadabilityDataset(train_df['processed_text'].tolist(), (train_df['Readability_Level_19'] - 1).tolist())
val_dataset = ReadabilityDataset(val_df['processed_text'].tolist(), (val_df['Readability_Level_19'] - 1).tolist())


training_args = TrainingArguments(
    output_dir=CHECKPOINT_DIR,
    num_train_epochs=6,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=32,
    learning_rate=5e-5,
    warmup_ratio=0.1,
    weight_decay=0.01,
    logging_steps=100,
    eval_strategy="epoch",
    save_strategy="epoch",
    load_best_model_at_end=True,
    metric_for_best_model="qwk",
    greater_is_better=True,
    save_total_limit=2,
    fp16=torch.cuda.is_available(),
    report_to="none"
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    compute_metrics=compute_metrics,
    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]
)

print("Starting training...")
trainer.train()
print("âœ” Training finished.")

# MODIFIED: Print QWK at the end based on the evaluation results on the validation set
eval_results = trainer.evaluate()
if "eval_qwk" in eval_results:
    print(f"\nQuadratic Weighted Kappa (QWK) on the development set: {eval_results['eval_qwk']:.4f}")
else:
    print("\nCould not retrieve QWK from evaluation results.")


# --- FINAL PREDICTION AND SUBMISSION (MODIFIED FOR CLASSIFICATION) ---
print("\n===== FINAL PREDICTION AND SUBMISSION =====\n")
try:
    print("Generating predictions on the test set...")
    # MODIFIED: Use the test_df loaded earlier
    test_dataset = ReadabilityDataset(test_df['processed_text'].tolist())
    predictions = trainer.predict(test_dataset)

    # MODIFIED: Use argmax to get the predicted class ID from the output logits.
    predicted_classes = np.argmax(predictions.predictions, axis=1)

    # MODIFIED: Convert predicted class IDs back to original scale (1-19)
    test_df['Prediction'] = (predicted_classes + 1).astype(int)

    # MODIFIED: Use the 'ID' column from the test_df for the submission file
    submission_df = test_df[['ID', 'Prediction']]
    submission_df = submission_df.rename(columns={'ID': 'Sentence ID'})

    print(f"Saving prediction file to: {SUBMISSION_PATH}")
    submission_df.to_csv(SUBMISSION_PATH, index=False)

    print(f"\nCompressing {os.path.basename(SUBMISSION_PATH)} into {os.path.basename(ZIPPED_SUBMISSION_PATH)}...")
    with zipfile.ZipFile(ZIPPED_SUBMISSION_PATH, 'w', zipfile.ZIP_DEFLATED) as zipf:
        zipf.write(SUBMISSION_PATH, arcname=os.path.basename(SUBMISSION_PATH))

    print(f"âœ” Submission file {os.path.basename(ZIPPED_SUBMISSION_PATH)} created successfully.")

except KeyError:
    print("! KEY ERROR: Could not find the 'ID' column in the test data. Please check the test.csv file.")
except Exception as e:
    print(f"An error occurred during final prediction: {e}")

print("\n--- Script Finished ---")