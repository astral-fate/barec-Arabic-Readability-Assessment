{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5660e3ca-9fdb-48fe-be69-9c3e5b005e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- üöÄ Starting SAMER Dataset D3Tok Pre-processing Script ---\n",
      "\n",
      "[1/5] Loading SAMER dataset from: D:\\arabic_readability_project\\data\\samer\\og\\samer_train.tsv\n",
      "‚úîÔ∏è  Data loaded successfully. Total records: 14343\n",
      "\n",
      "[2/5] Creating 'ID' and 'label' columns...\n",
      "‚úîÔ∏è 'ID' and 'label' columns created successfully.\n",
      "\n",
      "[3/5] Initializing BERT Disambiguator for preprocessing (CPU)...\n",
      "   (This may take a moment as the model is loaded into memory)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at C:\\Users\\Fatima\\AppData\\Roaming\\camel_tools\\data\\disambig_bert_unfactored\\msa were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úîÔ∏è Disambiguator loaded successfully.\n",
      "\n",
      "[4/5] Applying D3Tok analysis to 14343 text records from the 'Line' column...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40f2238c865e48c69f232931adede542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing Text with D3Tok:   0%|          | 0/14343 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úîÔ∏è D3Tok analysis complete.\n",
      "\n",
      "[5/5] Saving processed data to CSV file...\n",
      "‚úîÔ∏è  Successfully saved the file to: D:\\arabic_readability_project\\data\\samer\\samer_d3tok_processed.csv\n",
      "\n",
      "--- ‚úÖ Script Finished Successfully ---\n",
      "\n",
      "Preview of the first 5 rows of the processed data:\n",
      "   ID  label d3tok_text  Novel  Chapter  \\\n",
      "0   1      0                 0      2.0   \n",
      "1   2      0                 0      2.0   \n",
      "2   3      0                 0      2.0   \n",
      "3   4      0                 0      2.0   \n",
      "4   5      0                 0      2.0   \n",
      "\n",
      "                                                  L3  \\\n",
      "0                                       ÿßŸÑŸÅÿµŸÑ ÿßŸÑÿ´ÿßŸÜŸä   \n",
      "1                                       ¬´ŸàŸÉÿßŸÜ ÿµÿ®ÿßÿ≠..   \n",
      "2                                        ŸäŸàŸÖÿß Ÿàÿßÿ≠ÿØÿß¬ª   \n",
      "3  ŸÇÿ∂Ÿâ ŸÅÿ™ÿßŸÜÿß ÿ•ÿ®ÿ±ÿßŸáŸäŸÖ ‚Äî ŸàŸáÿ∞ÿß ÿßÿ≥ŸÖŸá ‚Äî ŸÑŸäŸÑÿ© ŸáÿßÿØÿ¶ÿ© ÿπŸÖŸä...   \n",
      "4                     ŸäŸÜÿ≠ÿØÿ± ÿπŸÑŸâ ÿ£ÿ≠ÿØ ÿ¨ÿßŸÜÿ®ŸäŸá ŸÜŸáÿ± Ÿáÿßÿ¶ÿ¨ÿå   \n",
      "\n",
      "                                                  L4  \\\n",
      "0                                       ÿßŸÑŸÅÿµŸÑ ÿßŸÑÿ´ÿßŸÜŸä   \n",
      "1                                       ¬´ŸàŸÉÿßŸÜ ÿµÿ®ÿßÿ≠..   \n",
      "2                                        ŸäŸàŸÖÿß Ÿàÿßÿ≠ÿØÿß¬ª   \n",
      "3  ŸÇÿ∂Ÿâ ŸÅÿ™ÿßŸÜÿß ÿ•ÿ®ÿ±ÿßŸáŸäŸÖ ‚Äî ŸàŸáÿ∞ÿß ÿßÿ≥ŸÖŸá ‚Äî ŸÑŸäŸÑÿ© ŸáÿßÿØÿ¶ÿ© ÿπŸÖŸä...   \n",
      "4                     ŸäŸÜÿ≠ÿØÿ± ÿπŸÑŸâ ÿ£ÿ≠ÿØ ÿ¨ÿßŸÜÿ®ŸäŸá ŸÜŸáÿ± Ÿáÿßÿ¶ÿ¨ÿå   \n",
      "\n",
      "                                                  L5  Line  \n",
      "0                                       ÿßŸÑŸÅÿµŸÑ ÿßŸÑÿ´ÿßŸÜŸä     0  \n",
      "1                                       ¬´ŸàŸÉÿßŸÜ ÿµÿ®ÿßÿ≠..     1  \n",
      "2                                        ŸäŸàŸÖÿß Ÿàÿßÿ≠ÿØÿß¬ª     1  \n",
      "3  ŸÇÿ∂Ÿâ ŸÅÿ™ÿßŸÜÿß ÿ•ÿ®ÿ±ÿßŸáŸäŸÖ ‚Äî ŸàŸáÿ∞ÿß ÿßÿ≥ŸÖŸá ‚Äî ŸÑŸäŸÑÿ© ŸáÿßÿØÿ¶ÿ© ÿπŸÖŸä...     2  \n",
      "4                     ŸäŸÜÿ≠ÿØÿ± ÿπŸÑŸâ ÿ£ÿ≠ÿØ ÿ¨ÿßŸÜÿ®ŸäŸá ŸÜŸáÿ± ÿ¨ÿßÿ¶ÿ¥ÿå     2  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "from camel_tools.disambig.bert import BERTUnfactoredDisambiguator\n",
    "from camel_tools.tokenizers.word import simple_word_tokenize\n",
    "from camel_tools.utils.dediac import dediac_ar\n",
    "import numpy as np # Imported numpy for efficient conditional logic\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for a cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =====================================================================================\n",
    "# 1. CONFIGURATION\n",
    "# =====================================================================================\n",
    "# IMPORTANT: Please ensure these paths are correct for your system.\n",
    "# Using raw string literals (r\"...\") is recommended on Windows to handle backslashes.\n",
    "DATA_DIR = r\"D:\\arabic_readability_project\\data\\samer\\og\"\n",
    "OUTPUT_DIR = r\"D:\\arabic_readability_project\\data\\samer\" # Directory to save the output file\n",
    "\n",
    "# --- Input File Path ---\n",
    "# Modified to point to the single SAMER training file\n",
    "SAMER_TRAIN_PATH = os.path.join(DATA_DIR, \"samer_train.tsv\")\n",
    "\n",
    "# --- Output File Path ---\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "OUTPUT_CSV_PATH = os.path.join(OUTPUT_DIR, \"samer_d3tok_processed.csv\")\n",
    "\n",
    "# =====================================================================================\n",
    "# 2. HELPER FUNCTION FOR D3TOK PREPROCESSING\n",
    "# =====================================================================================\n",
    "def preprocess_d3tok(text, disambiguator):\n",
    "    \"\"\"\n",
    "    Preprocesses a single string of text into the D3Tok format using\n",
    "    the provided BERTUnfactoredDisambiguator instance.\n",
    "    (This function remains unchanged as its logic is still applicable).\n",
    "    \"\"\"\n",
    "    # Ensure the input is a valid, non-empty string\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return \"\"\n",
    "    try:\n",
    "        # Tokenize the input text\n",
    "        tokens = simple_word_tokenize(text)\n",
    "        \n",
    "        # Disambiguate the tokens to get detailed analyses\n",
    "        disambiguated_sentence = disambiguator.disambiguate(tokens)\n",
    "        \n",
    "        d3tok_forms = []\n",
    "        for disambig_word in disambiguated_sentence:\n",
    "            # Check if the word has analyses and if 'd3tok' is available\n",
    "            if disambig_word.analyses and 'd3tok' in disambig_word.analyses[0][1]:\n",
    "                # Get the d3tok form, dediacritize it, and format spacing\n",
    "                d3tok = dediac_ar(disambig_word.analyses[0][1]['d3tok']).replace(\"_+\", \" +\").replace(\"+_\", \"+ \")\n",
    "                d3tok_forms.append(d3tok)\n",
    "            else:\n",
    "                # If no d3tok form, use the original word (e.g., for punctuation)\n",
    "                d3tok_forms.append(disambig_word.word)\n",
    "        \n",
    "        return \" \".join(d3tok_forms)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing text: '{text[:50]}...'. Error: {e}\")\n",
    "        return \"\" # Return an empty string in case of an error\n",
    "\n",
    "# =====================================================================================\n",
    "# 3. MAIN SCRIPT EXECUTION\n",
    "# =====================================================================================\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to load, process, and save the SAMER dataset.\n",
    "    \"\"\"\n",
    "    print(\"--- üöÄ Starting SAMER Dataset D3Tok Pre-processing Script ---\")\n",
    "\n",
    "    # --- Step 1: Load Data ---\n",
    "    print(f\"\\n[1/5] Loading SAMER dataset from: {SAMER_TRAIN_PATH}\")\n",
    "    try:\n",
    "        # Load the single TSV file. 'sep=\\t' specifies it's tab-separated.\n",
    "        df = pd.read_csv(SAMER_TRAIN_PATH, sep='\\t', on_bad_lines='warn')\n",
    "        print(f\"‚úîÔ∏è  Data loaded successfully. Total records: {len(df)}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"‚ùå ERROR: File not found. Please check your file path in the CONFIGURATION section.\")\n",
    "        print(f\"   - Missing file: {e.filename}\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERROR loading source data: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- Step 2: Create 'ID' and 'label' Columns ---\n",
    "    print(\"\\n[2/5] Creating 'ID' and 'label' columns...\")\n",
    "    \n",
    "    # Create a unique ID for each row. We'll use the dataframe index.\n",
    "    df['ID'] = df.index + 1\n",
    "\n",
    "    # Define the mapping from SAMER levels to BAREC scale\n",
    "    # L3 -> 4, L4 -> 10, L5 -> 16\n",
    "    conditions = [\n",
    "        df['L3'] == 'x',\n",
    "        df['L4'] == 'x',\n",
    "        df['L5'] == 'x'\n",
    "    ]\n",
    "    choices = [4, 10, 16]\n",
    "\n",
    "    # Use numpy.select for an efficient way to apply the logic\n",
    "    # It creates the 'label' column based on which of L3, L4, or L5 contains 'x'\n",
    "    # 'default=0' will be used if none of those columns have an 'x'\n",
    "    df['label'] = np.select(conditions, choices, default=0)\n",
    "    \n",
    "    print(\"‚úîÔ∏è 'ID' and 'label' columns created successfully.\")\n",
    "    \n",
    "    # --- Step 3: Initialize BERT Disambiguator ---\n",
    "    print(\"\\n[3/5] Initializing BERT Disambiguator for preprocessing (CPU)...\")\n",
    "    print(\"   (This may take a moment as the model is loaded into memory)\")\n",
    "    try:\n",
    "        bert_disambiguator = BERTUnfactoredDisambiguator.pretrained('msa')\n",
    "        print(\"‚úîÔ∏è Disambiguator loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERROR: Could not load the CAMeL Tools model. Please ensure it's installed correctly.\")\n",
    "        print(f\"   - To install: pip install camel-tools\")\n",
    "        print(f\"   - Error details: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- Step 4: Process the Text Data ---\n",
    "    print(f\"\\n[4/5] Applying D3Tok analysis to {len(df)} text records from the 'Line' column...\")\n",
    "    # Use tqdm's progress_apply to show a progress bar\n",
    "    tqdm.pandas(desc=\"Analyzing Text with D3Tok\")\n",
    "    \n",
    "    # Apply the preprocessing function to the 'Line' column\n",
    "    df['d3tok_text'] = df['Line'].progress_apply(\n",
    "        lambda text: preprocess_d3tok(text, bert_disambiguator)\n",
    "    )\n",
    "    print(\"‚úîÔ∏è D3Tok analysis complete.\")\n",
    "\n",
    "    # --- Step 5: Reorder Columns and Save the Processed Data ---\n",
    "    print(f\"\\n[5/5] Saving processed data to CSV file...\")\n",
    "    \n",
    "    # Define the desired order for the final CSV file\n",
    "    final_columns = [\n",
    "        'ID', \n",
    "        'label', \n",
    "        'd3tok_text', \n",
    "        'Novel', \n",
    "        'Chapter', \n",
    "        'L3', \n",
    "        'L4', \n",
    "        'L5', \n",
    "        'Line'\n",
    "    ]\n",
    "    df_final = df[final_columns]\n",
    "    \n",
    "    try:\n",
    "        df_final.to_csv(OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')\n",
    "        print(f\"‚úîÔ∏è  Successfully saved the file to: {OUTPUT_CSV_PATH}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERROR saving the output file: {e}\")\n",
    "        return\n",
    "        \n",
    "    print(\"\\n--- ‚úÖ Script Finished Successfully ---\")\n",
    "    print(\"\\nPreview of the first 5 rows of the processed data:\")\n",
    "    print(df_final.head())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (barec_env)",
   "language": "python",
   "name": "barec_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
