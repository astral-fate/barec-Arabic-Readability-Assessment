{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d469dc94-ec74-424d-82dc-efcb7a01d952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úîÔ∏è Configuration loaded. Using checkpoint: D:\\arabic_readability_project\\results\\hybrid_regression_readability-arabertv2-d3tok-reg\\checkpoint-48944\n",
      "\n",
      "===== üöÄ STARTING HYBRID DOCUMENT PREDICTION PIPELINE =====\n",
      "\n",
      "Initializing Tokenizer...\n",
      "Loading model weights from checkpoint: D:\\arabic_readability_project\\results\\hybrid_regression_readability-arabertv2-d3tok-reg\\checkpoint-48944\n",
      "‚úî Model loaded successfully.\n",
      "Loading document test data from: D:\\arabic_readability_project\\data\\doc_blind_test_data.csv\n",
      "Processing documents: splitting sentences and calculating lexical features...\n",
      "‚úî Successfully created 3,420 sentences with features from 100 documents.\n",
      "\n",
      "Generating predictions for all sentences...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregating results: finding the max readability score per document...\n",
      "\n",
      "Saving prediction file to: D:\\arabic_readability_project\\submission\\submission_hybrid_document.csv\n",
      "Compressing into submission_hybrid_document.zip...\n",
      "\n",
      "--- ‚úÖ SUCCESS! Submission file 'submission_hybrid_document.zip' created successfully. ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fatima\\AppData\\Local\\Temp\\ipykernel_21916\\1251622753.py:226: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  final_submission_df['Prediction'].fillna(1, inplace=True) # Default for docs with no text\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import zipfile\n",
    "import gc\n",
    "\n",
    "from torch.utils.data import Dataset as TorchDataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "from safetensors.torch import load_file\n",
    "# We need these from camel_tools for the feature calculation placeholder\n",
    "from camel_tools.tokenizers.word import simple_word_tokenize\n",
    "\n",
    "# =====================================================================================\n",
    "# 1. CONFIGURATION\n",
    "# =====================================================================================\n",
    "MODEL_NAME = \"CAMeL-Lab/readability-arabertv2-d3tok-reg\"\n",
    "TARGET_CLASSES = 19\n",
    "NUM_FEATURES = 7 # This MUST match your hybrid model's training\n",
    "\n",
    "# --- MODIFICATION: Set paths for your local machine ---\n",
    "# Use a raw string (r\"...\") for Windows paths to handle backslashes correctly\n",
    "CHECKPOINT_PATH = r\"D:\\arabic_readability_project\\results\\hybrid_regression_readability-arabertv2-d3tok-reg\\checkpoint-48944\"\n",
    "\n",
    "# Assuming your 'data' and 'submission' folders are in the same project directory\n",
    "BASE_DIR = r\"D:\\arabic_readability_project\" \n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
    "SUBMISSION_DIR = os.path.join(BASE_DIR, \"submission\")\n",
    "\n",
    "DOC_BLIND_TEST_PATH = os.path.join(DATA_DIR, 'doc_blind_test_data.csv')\n",
    "SUBMISSION_PATH = os.path.join(SUBMISSION_DIR, \"submission_hybrid_document.csv\")\n",
    "ZIPPED_SUBMISSION_PATH = os.path.join(SUBMISSION_DIR, \"submission_hybrid_document.zip\")\n",
    "\n",
    "os.makedirs(SUBMISSION_DIR, exist_ok=True)\n",
    "print(f\"‚úîÔ∏è Configuration loaded. Using checkpoint: {CHECKPOINT_PATH}\")\n",
    "\n",
    "\n",
    "# =====================================================================================\n",
    "# 2. FEATURE CALCULATION - !! ACTION REQUIRED !!\n",
    "# =====================================================================================\n",
    "def calculate_lexical_features(sentence_text):\n",
    "    \"\"\"\n",
    "    Calculates the 7 lexical features for a single sentence.\n",
    "\n",
    "    !!! IMPORTANT !!!\n",
    "    You MUST replace the logic in this function with the EXACT same feature\n",
    "    calculations you used to create your 'train_processed_full.csv' file.\n",
    "    The order and type of features must be identical.\n",
    "    \n",
    "    This placeholder function demonstrates the concept.\n",
    "    \"\"\"\n",
    "    # --- START OF PLACEHOLDER LOGIC ---\n",
    "    \n",
    "    # Example Feature 1: Word Count\n",
    "    words = simple_word_tokenize(sentence_text)\n",
    "    word_count = len(words)\n",
    "    \n",
    "    # Example Feature 2: Character Count\n",
    "    char_count = len(sentence_text)\n",
    "    \n",
    "    # Example Feature 3: Average Word Length\n",
    "    avg_word_len = np.mean([len(w) for w in words]) if words else 0\n",
    "\n",
    "    # ... and so on for the other 4 features.\n",
    "    \n",
    "    # The final list MUST contain exactly NUM_FEATURES (7) items.\n",
    "    # The dummy values below ensure the script runs. Replace them.\n",
    "    feature_vector = [\n",
    "        word_count,\n",
    "        char_count,\n",
    "        avg_word_len,\n",
    "        0, # Dummy feature 4\n",
    "        0, # Dummy feature 5\n",
    "        0, # Dummy feature 6\n",
    "        0, # Dummy feature 7\n",
    "    ]\n",
    "    \n",
    "    # --- END OF PLACEHOLDER LOGIC ---\n",
    "\n",
    "    return feature_vector\n",
    "\n",
    "\n",
    "# =====================================================================================\n",
    "# 3. HYBRID MODEL AND DATASET CLASSES\n",
    "# These definitions MUST match the ones used for training your hybrid model.\n",
    "# =====================================================================================\n",
    "\n",
    "class HybridRegressionModel(nn.Module):\n",
    "    \"\"\"This is the architecture from your successful notebook.\"\"\"\n",
    "    def __init__(self, model_name, num_extra_features):\n",
    "        super(HybridRegressionModel, self).__init__()\n",
    "        self.transformer = AutoModel.from_pretrained(model_name)\n",
    "        transformer_output_dim = self.transformer.config.hidden_size\n",
    "        # This complex head must match your trained model EXACTLY\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(transformer_output_dim + num_extra_features, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, features, labels=None):\n",
    "        transformer_outputs = self.transformer(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_embedding = transformer_outputs.last_hidden_state[:, 0, :]\n",
    "        combined_features = torch.cat([cls_embedding, features], dim=1)\n",
    "        logits = self.head(combined_features).squeeze(-1)\n",
    "\n",
    "        if labels is not None:\n",
    "            loss_fn = nn.MSELoss()\n",
    "            loss = loss_fn(logits, labels.float())\n",
    "            return (loss, logits)\n",
    "        return logits\n",
    "\n",
    "class ReadabilityDataset(TorchDataset):\n",
    "    \"\"\"Custom Dataset to format text and features for the hybrid model.\"\"\"\n",
    "    def __init__(self, texts, features, labels=None, tokenizer_obj=None, max_len=256):\n",
    "        self.texts = texts\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer_obj\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        feature_vec = torch.tensor(self.features[idx], dtype=torch.float)\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text, None, add_special_tokens=True, max_length=self.max_len,\n",
    "            padding='max_length', truncation=True, return_token_type_ids=True\n",
    "        )\n",
    "        item = {\n",
    "            'input_ids': torch.tensor(inputs['input_ids'], dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(inputs['attention_mask'], dtype=torch.long),\n",
    "            'features': feature_vec\n",
    "        }\n",
    "        if self.labels is not None:\n",
    "            item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        return item\n",
    "\n",
    "\n",
    "# =====================================================================================\n",
    "# 4. PREDICTION LOGIC\n",
    "# =====================================================================================\n",
    "\n",
    "def generate_document_predictions(checkpoint_path):\n",
    "    print(\"\\n===== üöÄ STARTING HYBRID DOCUMENT PREDICTION PIPELINE =====\\n\")\n",
    "    try:\n",
    "        # --- 1. Load Model and Tokenizer ---\n",
    "        print(\"Initializing Tokenizer...\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "        \n",
    "        print(f\"Loading model weights from checkpoint: {checkpoint_path}\")\n",
    "        model_weights_path = os.path.join(checkpoint_path, \"model.safetensors\")\n",
    "        if not os.path.exists(model_weights_path):\n",
    "            raise FileNotFoundError(f\"'model.safetensors' not found in the checkpoint directory.\")\n",
    "\n",
    "        model = HybridRegressionModel(MODEL_NAME, num_extra_features=NUM_FEATURES)\n",
    "        state_dict = load_file(model_weights_path)\n",
    "        model.load_state_dict(state_dict)\n",
    "        print(\"‚úî Model loaded successfully.\")\n",
    "        \n",
    "        # --- 2. Load and Process Document Data ---\n",
    "        print(f\"Loading document test data from: {DOC_BLIND_TEST_PATH}\")\n",
    "        doc_test_df = pd.read_csv(DOC_BLIND_TEST_PATH)\n",
    "        doc_test_df.dropna(subset=['ID', 'Sentences'], inplace=True)\n",
    "        \n",
    "        print(\"Processing documents: splitting sentences and calculating lexical features...\")\n",
    "        all_doc_ids = []\n",
    "        all_sentences = []\n",
    "        all_features = []\n",
    "        for _, row in doc_test_df.iterrows():\n",
    "            doc_id = row['ID']\n",
    "            full_text = row['Sentences']\n",
    "            \n",
    "            if isinstance(full_text, str) and full_text.strip():\n",
    "                sentences_list = [s.strip() for s in full_text.split('\\n') if s.strip()]\n",
    "                for sentence in sentences_list:\n",
    "                    # This is the new, critical step\n",
    "                    lexical_features = calculate_lexical_features(sentence)\n",
    "                    all_doc_ids.append(doc_id)\n",
    "                    all_sentences.append(sentence)\n",
    "                    all_features.append(lexical_features)\n",
    "\n",
    "        sentence_df = pd.DataFrame({\n",
    "            'doc_id': all_doc_ids,\n",
    "            'sentence_text': all_sentences,\n",
    "            'features': all_features\n",
    "        })\n",
    "        print(f\"‚úî Successfully created {len(sentence_df):,} sentences with features from {len(doc_test_df):,} documents.\")\n",
    "\n",
    "        # --- 3. Run Prediction ---\n",
    "        trainer = Trainer(model=model, args=TrainingArguments(output_dir=\"./temp_results\", per_device_eval_batch_size=32, report_to=\"none\"))\n",
    "        \n",
    "        print(\"\\nGenerating predictions for all sentences...\")\n",
    "        test_dataset = ReadabilityDataset(\n",
    "            texts=sentence_df['sentence_text'].tolist(),\n",
    "            features=sentence_df['features'].tolist(),\n",
    "            tokenizer_obj=tokenizer\n",
    "        )\n",
    "        raw_predictions = trainer.predict(test_dataset)\n",
    "        sentence_df['raw_prediction'] = raw_predictions.predictions.flatten()\n",
    "\n",
    "        # --- 4. Aggregate and Save Submission ---\n",
    "        print(\"Aggregating results: finding the max readability score per document...\")\n",
    "        doc_predictions = sentence_df.groupby('doc_id')['raw_prediction'].max()\n",
    "        \n",
    "        clipped_preds = np.clip(np.round(doc_predictions.values), 0, TARGET_CLASSES - 1)\n",
    "        final_labels = (clipped_preds + 1).astype(int)\n",
    "        \n",
    "        submission_df = pd.DataFrame({'Sentence ID': doc_predictions.index, 'Prediction': final_labels})\n",
    "        \n",
    "        # Merge to ensure all original IDs are present\n",
    "        final_submission_df = pd.DataFrame({'Sentence ID': doc_test_df['ID']}).merge(submission_df, on='Sentence ID', how='left')\n",
    "        final_submission_df['Prediction'].fillna(1, inplace=True) # Default for docs with no text\n",
    "        final_submission_df['Prediction'] = final_submission_df['Prediction'].astype(int)\n",
    "\n",
    "        print(f\"\\nSaving prediction file to: {SUBMISSION_PATH}\")\n",
    "        final_submission_df.to_csv(SUBMISSION_PATH, index=False)\n",
    "        \n",
    "        print(f\"Compressing into {os.path.basename(ZIPPED_SUBMISSION_PATH)}...\")\n",
    "        with zipfile.ZipFile(ZIPPED_SUBMISSION_PATH, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "            zipf.write(SUBMISSION_PATH, arcname=os.path.basename(SUBMISSION_PATH))\n",
    "        \n",
    "        print(f\"\\n--- ‚úÖ SUCCESS! Submission file '{os.path.basename(ZIPPED_SUBMISSION_PATH)}' created successfully. ---\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå An unexpected error occurred: {e}\")\n",
    "    finally:\n",
    "        gc.collect()\n",
    "        if 'model' in locals(): del model\n",
    "        if 'trainer' in locals(): del trainer\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "# =====================================================================================\n",
    "# 5. EXECUTE THE SCRIPT\n",
    "# =====================================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    generate_document_predictions(CHECKPOINT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdafc1b-6124-4551-8af0-f711e7437bec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09cf0b5d-113e-4677-b769-e5699abf37ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úîÔ∏è Configuration loaded. Using checkpoint: D:\\arabic_readability_project\\results\\hybrid_regression_readability-arabertv2-d3tok-reg\\checkpoint-48944\n",
      "\n",
      "===== üöÄ STARTING HYBRID DOCUMENT PREDICTION PIPELINE =====\n",
      "\n",
      "Loading model weights from checkpoint: D:\\arabic_readability_project\\results\\hybrid_regression_readability-arabertv2-d3tok-reg\\checkpoint-48944\n",
      "‚úî Model loaded successfully.\n",
      "Processing documents: splitting sentences and calculating features...\n",
      "‚úî Successfully created 3420 sentences with features.\n",
      "\n",
      "--- Saving ALL processed data for review to: review_full_pipeline_output.csv ---\n",
      "‚úî Review file saved. Please inspect it for errors in 'features' and 'processed_text'.\n",
      "\n",
      "Generating predictions for all sentences...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregating results...\n",
      "\n",
      "Saving prediction file to: D:\\arabic_readability_project\\submission\\submission_hybrid_document.csv\n",
      "\n",
      "--- ‚úÖ SUCCESS! Submission file 'submission_hybrid_document.zip' created. ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import zipfile\n",
    "import gc\n",
    "\n",
    "from torch.utils.data import Dataset as TorchDataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "from safetensors.torch import load_file\n",
    "from camel_tools.tokenizers.word import simple_word_tokenize\n",
    "\n",
    "# =====================================================================================\n",
    "# 1. CONFIGURATION\n",
    "# =====================================================================================\n",
    "MODEL_NAME = \"CAMeL-Lab/readability-arabertv2-d3tok-reg\"\n",
    "TARGET_CLASSES = 19\n",
    "NUM_FEATURES = 7\n",
    "CHECKPOINT_PATH = r\"D:\\arabic_readability_project\\results\\hybrid_regression_readability-arabertv2-d3tok-reg\\checkpoint-48944\"\n",
    "BASE_DIR = r\"D:\\arabic_readability_project\" \n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
    "SUBMISSION_DIR = os.path.join(BASE_DIR, \"submission\")\n",
    "DOC_BLIND_TEST_PATH = os.path.join(DATA_DIR, 'doc_blind_test_data.csv')\n",
    "SUBMISSION_PATH = os.path.join(SUBMISSION_DIR, \"submission_hybrid_document.csv\")\n",
    "ZIPPED_SUBMISSION_PATH = os.path.join(SUBMISSION_DIR, \"submission_hybrid_document.zip\")\n",
    "\n",
    "os.makedirs(SUBMISSION_DIR, exist_ok=True)\n",
    "print(f\"‚úîÔ∏è Configuration loaded. Using checkpoint: {CHECKPOINT_PATH}\")\n",
    "\n",
    "\n",
    "# =====================================================================================\n",
    "# 2. FEATURE CALCULATION - !! THIS IS THE MOST LIKELY PROBLEM AREA !!\n",
    "# =====================================================================================\n",
    "def calculate_lexical_features(sentence_text):\n",
    "    \"\"\"\n",
    "    You MUST replace this with the EXACT feature calculation logic from your training notebook.\n",
    "    \"\"\"\n",
    "    words = simple_word_tokenize(sentence_text)\n",
    "    word_count = len(words)\n",
    "    char_count = len(sentence_text)\n",
    "    avg_word_len = np.mean([len(w) for w in words]) if words else 0\n",
    "    \n",
    "    # The dummy values below ensure the script runs. Replace them.\n",
    "    feature_vector = [word_count, char_count, avg_word_len, 0, 0, 0, 0]\n",
    "    return feature_vector\n",
    "\n",
    "\n",
    "# =====================================================================================\n",
    "# 3. HYBRID MODEL AND DATASET CLASSES (These must match your training setup)\n",
    "# =====================================================================================\n",
    "\n",
    "class HybridRegressionModel(nn.Module):\n",
    "    def __init__(self, model_name, num_extra_features):\n",
    "        super(HybridRegressionModel, self).__init__()\n",
    "        self.transformer = AutoModel.from_pretrained(model_name)\n",
    "        transformer_output_dim = self.transformer.config.hidden_size\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(transformer_output_dim + num_extra_features, 512),\n",
    "            nn.BatchNorm1d(512), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256), nn.ReLU(), nn.Dropout(0.2),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "    def forward(self, input_ids, attention_mask, features, labels=None):\n",
    "        transformer_outputs = self.transformer(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_embedding = transformer_outputs.last_hidden_state[:, 0, :]\n",
    "        combined_features = torch.cat([cls_embedding, features], dim=1)\n",
    "        logits = self.head(combined_features).squeeze(-1)\n",
    "        if labels is not None:\n",
    "            loss = nn.MSELoss()(logits, labels.float())\n",
    "            return (loss, logits)\n",
    "        return logits\n",
    "\n",
    "class ReadabilityDataset(TorchDataset):\n",
    "    def __init__(self, texts, features, labels=None, tokenizer_obj=None, max_len=256):\n",
    "        self.texts = texts; self.features = features; self.labels = labels\n",
    "        self.tokenizer = tokenizer_obj; self.max_len = max_len\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        feature_vec = torch.tensor(self.features[idx], dtype=torch.float)\n",
    "        inputs = self.tokenizer.encode_plus(text, None, add_special_tokens=True, max_length=self.max_len, padding='max_length', truncation=True)\n",
    "        item = {\n",
    "            'input_ids': torch.tensor(inputs['input_ids'], dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(inputs['attention_mask'], dtype=torch.long),\n",
    "            'features': feature_vec\n",
    "        }\n",
    "        if self.labels is not None:\n",
    "            item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        return item\n",
    "\n",
    "# Dummy d3tok function since it's not available locally but was part of your training\n",
    "# We will use the raw sentence text instead, which is a better test anyway.\n",
    "def dummy_preprocess_d3tok(text):\n",
    "    return text\n",
    "\n",
    "\n",
    "# =====================================================================================\n",
    "# 4. PREDICTION LOGIC WITH DEBUGGING OUTPUT\n",
    "# =====================================================================================\n",
    "\n",
    "def generate_document_predictions(checkpoint_path):\n",
    "    print(\"\\n===== üöÄ STARTING HYBRID DOCUMENT PREDICTION PIPELINE =====\\n\")\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "        print(f\"Loading model weights from checkpoint: {checkpoint_path}\")\n",
    "        model = HybridRegressionModel(MODEL_NAME, num_extra_features=NUM_FEATURES)\n",
    "        model.load_state_dict(load_file(os.path.join(checkpoint_path, \"model.safetensors\")))\n",
    "        print(\"‚úî Model loaded successfully.\")\n",
    "        \n",
    "        doc_test_df = pd.read_csv(DOC_BLIND_TEST_PATH)\n",
    "        doc_test_df.dropna(subset=['ID', 'Sentences'], inplace=True)\n",
    "        \n",
    "        print(\"Processing documents: splitting sentences and calculating features...\")\n",
    "        rows_for_df = []\n",
    "        for _, row in doc_test_df.iterrows():\n",
    "            doc_id = row['ID']\n",
    "            full_text = row['Sentences']\n",
    "            if isinstance(full_text, str) and full_text.strip():\n",
    "                sentences_list = [s.strip() for s in full_text.split('\\n') if s.strip()]\n",
    "                for sentence in sentences_list:\n",
    "                    features = calculate_lexical_features(sentence)\n",
    "                    # For debugging, we use the raw text, not a d3tok version\n",
    "                    processed_text = dummy_preprocess_d3tok(sentence)\n",
    "                    rows_for_df.append({\n",
    "                        'doc_id': doc_id,\n",
    "                        'sentence_text': sentence,\n",
    "                        'features': features,\n",
    "                        'processed_text': processed_text\n",
    "                    })\n",
    "\n",
    "        if not rows_for_df:\n",
    "            raise ValueError(\"No sentences could be extracted from the document file.\")\n",
    "            \n",
    "        sentence_df = pd.DataFrame(rows_for_df)\n",
    "        print(f\"‚úî Successfully created {len(sentence_df)} sentences with features.\")\n",
    "\n",
    "        # --- NEW: Save the comprehensive review file ---\n",
    "        review_path = 'review_full_pipeline_output.csv'\n",
    "        print(f\"\\n--- Saving ALL processed data for review to: {review_path} ---\")\n",
    "        sentence_df.to_csv(review_path, index=False, encoding='utf-8-sig')\n",
    "        print(\"‚úî Review file saved. Please inspect it for errors in 'features' and 'processed_text'.\")\n",
    "\n",
    "        trainer = Trainer(model=model, args=TrainingArguments(output_dir=\"./temp_results\", per_device_eval_batch_size=32, report_to=\"none\"))\n",
    "        \n",
    "        print(\"\\nGenerating predictions for all sentences...\")\n",
    "        test_dataset = ReadabilityDataset(\n",
    "            texts=sentence_df['processed_text'].tolist(),\n",
    "            features=sentence_df['features'].tolist(),\n",
    "            tokenizer_obj=tokenizer\n",
    "        )\n",
    "        raw_predictions = trainer.predict(test_dataset)\n",
    "        sentence_df['raw_prediction'] = raw_predictions.predictions.flatten()\n",
    "\n",
    "        print(\"Aggregating results...\")\n",
    "        doc_predictions = sentence_df.groupby('doc_id')['raw_prediction'].max()\n",
    "        \n",
    "        clipped_preds = np.clip(np.round(doc_predictions.values), 0, TARGET_CLASSES - 1)\n",
    "        final_labels = (clipped_preds + 1).astype(int)\n",
    "        \n",
    "        submission_df = pd.DataFrame({'Sentence ID': doc_predictions.index, 'Prediction': final_labels})\n",
    "        \n",
    "        final_submission_df = pd.DataFrame({'Sentence ID': doc_test_df['ID']}).merge(submission_df, on='Sentence ID', how='left')\n",
    "        # FIX: Correct way to handle fillna to avoid FutureWarnings\n",
    "        final_submission_df['Prediction'] = final_submission_df['Prediction'].fillna(1)\n",
    "        final_submission_df['Prediction'] = final_submission_df['Prediction'].astype(int)\n",
    "\n",
    "        print(f\"\\nSaving prediction file to: {SUBMISSION_PATH}\")\n",
    "        final_submission_df.to_csv(SUBMISSION_PATH, index=False)\n",
    "        \n",
    "        with zipfile.ZipFile(ZIPPED_SUBMISSION_PATH, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "            zipf.write(SUBMISSION_PATH, arcname=os.path.basename(SUBMISSION_PATH))\n",
    "        \n",
    "        print(f\"\\n--- ‚úÖ SUCCESS! Submission file '{os.path.basename(ZIPPED_SUBMISSION_PATH)}' created. ---\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå An unexpected error occurred: {e}\")\n",
    "    finally:\n",
    "        gc.collect()\n",
    "        if 'model' in locals(): del model\n",
    "        if 'trainer' in locals(): del trainer\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "# =====================================================================================\n",
    "# 5. EXECUTE THE SCRIPT\n",
    "# =====================================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    generate_document_predictions(CHECKPOINT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544a2ee7-15c0-4630-9e53-7ccb4ed9f0a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1b431e-e7e3-45a1-a3f7-1ddcd32206b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the document on the Hybrid Model trained on samer + samer lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0af4c63a-f13e-4a83-ab31-3a19359264d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úîÔ∏è Configuration loaded. Using checkpoint: D:\\arabic_readability_project\\results\\hybrid_regression_readability-arabertv2-d3tok-reg\\checkpoint-48944\n",
      "\n",
      "===== üöÄ STARTING HYBRID DOCUMENT PREDICTION PIPELINE =====\n",
      "\n",
      "Initializing Tokenizer and Disambiguator...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at C:\\Users\\Fatima\\AppData\\Roaming\\camel_tools\\data\\disambig_bert_unfactored\\msa were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SAMER Lexicon from: D:\\arabic_readability_project\\data\\samer_lexicon.tsv\n",
      "Loading model weights from checkpoint: D:\\arabic_readability_project\\results\\hybrid_regression_readability-arabertv2-d3tok-reg\\checkpoint-48944\n",
      "‚úî All models and data loaded successfully.\n",
      "\n",
      "Processing documents: this will take time...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "566119558c9d47d48764f95cdddee801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Documents:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úî Successfully created 3420 sentences with features.\n",
      "\n",
      "Generating predictions for all sentences...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregating results...\n",
      "\n",
      "Saving prediction file to: D:\\arabic_readability_project\\submission\\submission_hybrid_document_final.csv\n",
      "\n",
      "--- ‚úÖ SUCCESS! Submission file 'submission_hybrid_document_final.zip' created. ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import zipfile\n",
    "import gc\n",
    "\n",
    "from torch.utils.data import Dataset as TorchDataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "from safetensors.torch import load_file\n",
    "from camel_tools.disambig.bert import BERTUnfactoredDisambiguator\n",
    "from camel_tools.tokenizers.word import simple_word_tokenize\n",
    "from camel_tools.utils.dediac import dediac_ar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# =====================================================================================\n",
    "# 1. CONFIGURATION\n",
    "# =====================================================================================\n",
    "MODEL_NAME = \"CAMeL-Lab/readability-arabertv2-d3tok-reg\"\n",
    "TARGET_CLASSES = 19\n",
    "NUM_FEATURES = 7 \n",
    "\n",
    "CHECKPOINT_PATH = r\"D:\\arabic_readability_project\\results\\hybrid_regression_readability-arabertv2-d3tok-reg\\checkpoint-48944\"\n",
    "BASE_DIR = r\"D:\\arabic_readability_project\" \n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
    "SUBMISSION_DIR = os.path.join(BASE_DIR, \"submission\")\n",
    "\n",
    "DOC_BLIND_TEST_PATH = os.path.join(DATA_DIR, 'doc_blind_test_data.csv')\n",
    "SAMER_LEXICON_PATH = os.path.join(DATA_DIR, 'samer_lexicon.tsv') \n",
    "\n",
    "SUBMISSION_PATH = os.path.join(SUBMISSION_DIR, \"submission_hybrid_document_final.csv\")\n",
    "ZIPPED_SUBMISSION_PATH = os.path.join(SUBMISSION_DIR, \"submission_hybrid_document_final.zip\")\n",
    "\n",
    "os.makedirs(SUBMISSION_DIR, exist_ok=True)\n",
    "print(f\"‚úîÔ∏è Configuration loaded. Using checkpoint: {CHECKPOINT_PATH}\")\n",
    "\n",
    "\n",
    "# =====================================================================================\n",
    "# 2. FEATURE CALCULATION - WITH THE FINAL API FIX\n",
    "# =====================================================================================\n",
    "def calculate_features_and_d3tok(sentence_text, disambiguator, lexicon_map):\n",
    "    if not isinstance(sentence_text, str) or not sentence_text.strip():\n",
    "        return ([0.0] * NUM_FEATURES, \"\")\n",
    "\n",
    "    try:\n",
    "        # --- THE FINAL FIX IS HERE ---\n",
    "        # Pass the flat list of tokens directly to the disambiguator.\n",
    "        tokens = simple_word_tokenize(sentence_text)\n",
    "        disambiguated_sentence = disambiguator.disambiguate(tokens)\n",
    "\n",
    "        d3tok_forms = []\n",
    "        for da in disambiguated_sentence:\n",
    "            if da.analyses and 'd3tok' in da.analyses[0][1]:\n",
    "                d3tok_value = da.analyses[0][1]['d3tok']\n",
    "                if isinstance(d3tok_value, str):\n",
    "                    d3tok_forms.append(dediac_ar(d3tok_value).replace(\"_+\", \" +\").replace(\"+_\", \"+ \"))\n",
    "                elif isinstance(da.word, str): d3tok_forms.append(da.word)\n",
    "            elif isinstance(da.word, str): d3tok_forms.append(da.word)\n",
    "        d3tok_text = \" \".join(d3tok_forms)\n",
    "\n",
    "        scores = []\n",
    "        for dw in disambiguated_sentence:\n",
    "            if dw.analyses:\n",
    "                analysis = dw.analyses[0][1]\n",
    "                lemma, pos = analysis.get('lex'), analysis.get('pos')\n",
    "                if pos and isinstance(lemma, str):\n",
    "                    score = lexicon_map.get(f\"{dediac_ar(lemma)}#{pos}\")\n",
    "                    if score is not None: scores.append(score)\n",
    "        \n",
    "        avg_readability = np.mean(scores) if scores else 0.0\n",
    "        max_readability = np.max(scores) if scores else 0.0\n",
    "\n",
    "        # !!! ACTION REQUIRED: Add your other 5 features here !!!\n",
    "        feature_3, feature_4, feature_5, feature_6, feature_7 = 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "        feature_vector = [avg_readability, max_readability, feature_3, feature_4, feature_5, feature_6, feature_7]\n",
    "        \n",
    "        return feature_vector, d3tok_text\n",
    "\n",
    "    except TypeError as e:\n",
    "        error_message = f\"A TypeError occurred processing sentence: >>>{sentence_text}<<< Original error: {e}\"\n",
    "        raise TypeError(error_message)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: An error '{e}' occurred on sentence: '{sentence_text}'. Skipping.\")\n",
    "        return ([0.0] * NUM_FEATURES, \"\")\n",
    "\n",
    "\n",
    "# =====================================================================================\n",
    "# 3. HYBRID MODEL AND DATASET CLASSES (Copied from your notebook)\n",
    "# =====================================================================================\n",
    "\n",
    "class HybridRegressionModel(nn.Module):\n",
    "    def __init__(self, model_name, num_extra_features):\n",
    "        super(HybridRegressionModel, self).__init__()\n",
    "        self.transformer = AutoModel.from_pretrained(model_name)\n",
    "        transformer_output_dim = self.transformer.config.hidden_size\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(transformer_output_dim + num_extra_features, 512),\n",
    "            nn.BatchNorm1d(512), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256), nn.ReLU(), nn.Dropout(0.2),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "    def forward(self, input_ids, attention_mask, features, labels=None):\n",
    "        transformer_outputs = self.transformer(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_embedding = transformer_outputs.last_hidden_state[:, 0, :]\n",
    "        combined_features = torch.cat([cls_embedding, features], dim=1)\n",
    "        logits = self.head(combined_features).squeeze(-1)\n",
    "        if labels is not None:\n",
    "            loss = nn.MSELoss()(logits, labels.float())\n",
    "            return (loss, logits)\n",
    "        return logits\n",
    "\n",
    "class ReadabilityDataset(TorchDataset):\n",
    "    def __init__(self, texts, features, labels=None, tokenizer_obj=None, max_len=256):\n",
    "        self.texts=texts; self.features=features; self.labels=labels\n",
    "        self.tokenizer=tokenizer_obj; self.max_len=max_len\n",
    "    def __len__(self): return len(self.texts)\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        feature_vec = torch.tensor(self.features[idx], dtype=torch.float)\n",
    "        inputs = self.tokenizer.encode_plus(text, None, add_special_tokens=True, max_length=self.max_len, padding='max_length', truncation=True)\n",
    "        item = {'input_ids': torch.tensor(inputs['input_ids'], dtype=torch.long),\n",
    "                'attention_mask': torch.tensor(inputs['attention_mask'], dtype=torch.long),\n",
    "                'features': feature_vec}\n",
    "        if self.labels is not None: item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        return item\n",
    "\n",
    "\n",
    "# =====================================================================================\n",
    "# 4. PREDICTION LOGIC\n",
    "# =====================================================================================\n",
    "\n",
    "def generate_document_predictions(checkpoint_path):\n",
    "    print(\"\\n===== üöÄ STARTING HYBRID DOCUMENT PREDICTION PIPELINE =====\\n\")\n",
    "    try:\n",
    "        print(\"Initializing Tokenizer and Disambiguator...\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "        disambiguator = BERTUnfactoredDisambiguator.pretrained('msa')\n",
    "        \n",
    "        print(f\"Loading SAMER Lexicon from: {SAMER_LEXICON_PATH}\")\n",
    "        lexicon_df = pd.read_csv(SAMER_LEXICON_PATH, sep='\\t')\n",
    "        lexicon_map = lexicon_df.set_index('lemma#pos')['readability (rounded average)'].to_dict()\n",
    "        \n",
    "        print(f\"Loading model weights from checkpoint: {checkpoint_path}\")\n",
    "        model = HybridRegressionModel(MODEL_NAME, num_extra_features=NUM_FEATURES)\n",
    "        model.load_state_dict(load_file(os.path.join(checkpoint_path, \"model.safetensors\")))\n",
    "        print(\"‚úî All models and data loaded successfully.\")\n",
    "        \n",
    "        doc_test_df = pd.read_csv(DOC_BLIND_TEST_PATH)\n",
    "        doc_test_df.dropna(subset=['ID', 'Sentences'], inplace=True)\n",
    "        \n",
    "        print(\"\\nProcessing documents: this will take time...\")\n",
    "        rows_for_df = []\n",
    "        for _, row in tqdm(doc_test_df.iterrows(), total=len(doc_test_df), desc=\"Processing Documents\"):\n",
    "            doc_id = row['ID']\n",
    "            full_text = row['Sentences']\n",
    "            if isinstance(full_text, str) and full_text.strip():\n",
    "                sentences_list = [s.strip() for s in full_text.split('\\n') if s.strip()]\n",
    "                for sentence in sentences_list:\n",
    "                    features, processed_text = calculate_features_and_d3tok(sentence, disambiguator, lexicon_map)\n",
    "                    rows_for_df.append({'doc_id': doc_id, 'features': features, 'processed_text': processed_text})\n",
    "\n",
    "        if not rows_for_df: raise ValueError(\"No sentences could be extracted.\")\n",
    "        sentence_df = pd.DataFrame(rows_for_df)\n",
    "        print(f\"‚úî Successfully created {len(sentence_df)} sentences with features.\")\n",
    "\n",
    "        trainer = Trainer(model=model, args=TrainingArguments(output_dir=\"./temp_results\", per_device_eval_batch_size=32, report_to=\"none\"))\n",
    "        \n",
    "        print(\"\\nGenerating predictions for all sentences...\")\n",
    "        test_dataset = ReadabilityDataset(texts=sentence_df['processed_text'].tolist(), features=sentence_df['features'].tolist(), tokenizer_obj=tokenizer)\n",
    "        raw_predictions = trainer.predict(test_dataset)\n",
    "        sentence_df['raw_prediction'] = raw_predictions.predictions.flatten()\n",
    "\n",
    "        print(\"Aggregating results...\")\n",
    "        doc_predictions = sentence_df.groupby('doc_id')['raw_prediction'].max()\n",
    "        \n",
    "        clipped_preds = np.clip(np.round(doc_predictions.values), 0, TARGET_CLASSES - 1)\n",
    "        final_labels = (clipped_preds + 1).astype(int)\n",
    "        \n",
    "        submission_df = pd.DataFrame({'Sentence ID': doc_predictions.index, 'Prediction': final_labels})\n",
    "        final_submission_df = pd.DataFrame({'Sentence ID': doc_test_df['ID']}).merge(submission_df, on='Sentence ID', how='left')\n",
    "        final_submission_df['Prediction'] = final_submission_df['Prediction'].fillna(1).astype(int)\n",
    "\n",
    "        print(f\"\\nSaving prediction file to: {SUBMISSION_PATH}\")\n",
    "        final_submission_df.to_csv(SUBMISSION_PATH, index=False)\n",
    "        \n",
    "        with zipfile.ZipFile(ZIPPED_SUBMISSION_PATH, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "            zipf.write(SUBMISSION_PATH, arcname=os.path.basename(SUBMISSION_PATH))\n",
    "        \n",
    "        print(f\"\\n--- ‚úÖ SUCCESS! Submission file '{os.path.basename(ZIPPED_SUBMISSION_PATH)}' created. ---\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå An unexpected error occurred: {e}\")\n",
    "    finally:\n",
    "        gc.collect()\n",
    "        if 'model' in locals(): del model\n",
    "        if 'trainer' in locals(): del trainer\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "# =====================================================================================\n",
    "# 5. EXECUTE THE SCRIPT\n",
    "# =====================================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    generate_document_predictions(CHECKPOINT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7704a1-b458-492e-83f0-c86c5566379e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (barec_env)",
   "language": "python",
   "name": "barec_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
